{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Randomized search notebook\n",
    "author: Gonzalo Miranda Cabrera\n",
    "\n",
    "objective: perform a randomized search on three regressors to find a rough idea of the parameters to use.\n",
    "\n",
    "summary:\n",
    "1. split data into train and test.\n",
    "2. define the pipelines to be trained.\n",
    "3. define de parameters for each pipeline and the parameters of the randomized search.\n",
    "4. train the pipelines.\n",
    "5. write results to a file.\n",
    "6. save models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split data into train and test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "data = pd.read_csv(\"data.csv\", index_col=\"order_id\")\n",
    "\n",
    "y = data.pop(\"total_minutes\").to_numpy()\n",
    "X = data.to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=0)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((4549, 37), (3034, 37), (4549,), (3034,))"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define pipelines"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline composition\n",
    "1. Standard scaler -> standardizes the data with mean and std\n",
    "2. PCA -> Principal component analysis (change of basis on the input data)\n",
    "3. ML Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "svm_pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"pca\", PCA()), (\"svm\", SVR())])\n",
    "rfr_pipeline = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), (\"pca\", PCA()), (\"rfr\", RandomForestRegressor())]\n",
    ")\n",
    "xgb_pipeline = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), (\"pca\", PCA()), (\"xgb\", XGBRegressor())]\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Randomized search"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A random search is performed to find the best hyperparameters.\n",
    "\n",
    "The random search only lasts for 6000 iterations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "svm_params = {\n",
    "    \"pca__n_components\": [5, 10, 15, 20, 25, 30, 35, 37],\n",
    "    \"svm__C\": [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 30, 32, 35],\n",
    "    \"svm__epsilon\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"svm__gamma\": [\"scale\", \"auto\"],\n",
    "    \"svm__kernel\": [\"linear\", \"sigmoid\", \"rbf\"],\n",
    "    \"svm__shrinking\": [True, False],\n",
    "}\n",
    "\n",
    "rfr_params = {\n",
    "    \"pca__n_components\": [5, 10, 15, 20, 25, 30, 35, 37],\n",
    "    \"rfr__n_estimators\": [\n",
    "        100,\n",
    "        200,\n",
    "        300,\n",
    "        400,\n",
    "        500,\n",
    "        600,\n",
    "        700,\n",
    "        800,\n",
    "        900,\n",
    "        1000,\n",
    "        1100,\n",
    "        1200,\n",
    "        1300,\n",
    "        1400,\n",
    "        1500,\n",
    "        1600,\n",
    "        1700,\n",
    "        1800,\n",
    "        1900,\n",
    "    ],\n",
    "    \"rfr__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"rfr__max_depth\": [10, 20, 30, 40, 50, 60, 70, 80, 90, None],\n",
    "    \"rfr__min_samples_split\": [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"rfr__min_samples_leaf\": [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    \"rfr__bootstrap\": [True, False],\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    \"pca__n_components\": [5, 10, 15, 20, 25, 30, 35, 37],\n",
    "    \"xgb__objective\": [\"reg:squarederror\", \"reg:squaredlogerror\"],\n",
    "    \"xgb__learning_rate\": [0.01, 0.005, 0.001],\n",
    "    \"xgb__max_depth\": [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    \"xgb__min_child_weight\": [3, 4, 5, 6, 7, 8, 9],\n",
    "    \"xgb__subsample\": [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"xgb__colsample_bytree\": [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"xgb__n_estimators\": [\n",
    "        100,\n",
    "        200,\n",
    "        300,\n",
    "        400,\n",
    "        500,\n",
    "        600,\n",
    "        700,\n",
    "        800,\n",
    "        900,\n",
    "        1000,\n",
    "        1100,\n",
    "        1200,\n",
    "        1300,\n",
    "        1400,\n",
    "        1500,\n",
    "        1600,\n",
    "        1700,\n",
    "        1800,\n",
    "        1900,\n",
    "    ],\n",
    "    \"xgb__n_jobs\": [2],\n",
    "}\n",
    "\n",
    "\n",
    "svm_random_search = RandomizedSearchCV(\n",
    "    estimator=svm_pipeline,\n",
    "    param_distributions=svm_params,\n",
    "    scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\", \"r2\"],\n",
    "    refit=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    n_iter=6000,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "rfr_random_search = RandomizedSearchCV(\n",
    "    estimator=rfr_pipeline,\n",
    "    param_distributions=rfr_params,\n",
    "    scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\", \"r2\"],\n",
    "    refit=\"neg_root_mean_squared_error\",\n",
    "    n_iter=6000,\n",
    "    cv=3,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "\n",
    "xgb_random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_pipeline,\n",
    "    param_distributions=xgb_params,\n",
    "    scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\", \"r2\"],\n",
    "    refit=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    n_iter=6000,\n",
    "    random_state=0,\n",
    "    n_jobs=6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"svm started random search\")\n",
    "svm_random_search.fit(x_train, y_train)\n",
    "print(\"random forest started random search\")\n",
    "rfr_random_search.fit(x_train, y_train)\n",
    "print(\"xgb regressor started random search\")\n",
    "xgb_random_search.fit(x_train, y_train)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "svm started random search\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "random forest started random search\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "xgb regressor started random search\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                             ('pca', PCA()),\n",
       "                                             ('xgb',\n",
       "                                              XGBRegressor(base_score=None,\n",
       "                                                           booster=None,\n",
       "                                                           colsample_bylevel=None,\n",
       "                                                           colsample_bynode=None,\n",
       "                                                           colsample_bytree=None,\n",
       "                                                           gamma=None,\n",
       "                                                           gpu_id=None,\n",
       "                                                           importance_type='gain',\n",
       "                                                           interaction_constraints=None,\n",
       "                                                           learning_rate=None,\n",
       "                                                           max_delta_step=None,\n",
       "                                                           max_depth=None,\n",
       "                                                           min_child_wei...\n",
       "                                        'xgb__n_estimators': [100, 200, 300,\n",
       "                                                              400, 500, 600,\n",
       "                                                              700, 800, 900,\n",
       "                                                              1000, 1100, 1200,\n",
       "                                                              1300, 1400, 1500,\n",
       "                                                              1600, 1700, 1800,\n",
       "                                                              1900],\n",
       "                                        'xgb__n_jobs': [2],\n",
       "                                        'xgb__objective': ['reg:squarederror',\n",
       "                                                           'reg:squaredlogerror'],\n",
       "                                        'xgb__subsample': [0.3, 0.4, 0.5, 0.6,\n",
       "                                                           0.7, 0.8, 0.9]},\n",
       "                   random_state=0, refit='neg_root_mean_squared_error',\n",
       "                   scoring=['neg_mean_absolute_error',\n",
       "                            'neg_root_mean_squared_error', 'r2'],\n",
       "                   verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Best scores on training data\n",
    "print(f\"svm rmse: {svm_random_search.best_score_}\")\n",
    "print(f\"rfr rmse: {rfr_random_search.best_score_}\")\n",
    "print(f\"xgb rmse: {xgb_random_search.best_score_}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "svm rmse: -24.826498717941266\n",
      "rfr rmse: -24.75567138070458\n",
      "xgb rmse: -24.71352189051753\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# mae and mse on test data\n",
    "\n",
    "original_stdout = sys.stdout  # Save a reference to the original standard output\n",
    "\n",
    "models = [\n",
    "    (\"svm\", svm_random_search),\n",
    "    (\"rfr\", rfr_random_search),\n",
    "    (\"xgb\", xgb_random_search),\n",
    "]\n",
    "\n",
    "\n",
    "def ensemble_predict(pred):\n",
    "    return (\n",
    "        sum(\n",
    "            [\n",
    "                svm_random_search.best_estimator_.predict(pred),\n",
    "                rfr_random_search.best_estimator_.predict(pred),\n",
    "                xgb_random_search.best_estimator_.predict(pred),\n",
    "            ]\n",
    "        )\n",
    "        / 3\n",
    "    )\n",
    "\n",
    "\n",
    "with open(\"rand_search_results/results.txt\", \"w\") as f:\n",
    "    sys.stdout = f  # Change the standard output to the file we created.\n",
    "\n",
    "    # Mean absolute error\n",
    "    for model in models:\n",
    "        print(\n",
    "            f\"{model[0]} mae\",\n",
    "            f\"{mean_absolute_error(y_true=y_test, y_pred=model[1].best_estimator_.predict(x_test))}\",\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"ensemble mae: {mean_absolute_error(y_true=y_test, y_pred=ensemble_predict(x_test))}\"\n",
    "    )\n",
    "\n",
    "    # Root mean squared error\n",
    "    for model in models:\n",
    "        print(\n",
    "            f\"{model[0]} rmse\",\n",
    "            f\"{mean_squared_error(y_true=y_test, y_pred=model[1].best_estimator_.predict(x_test),squared=False)}\",\n",
    "        )\n",
    "    print(\n",
    "        f\"ensemble rmse: {mean_squared_error(y_true=y_test, y_pred=ensemble_predict(x_test), squared=False)}\"\n",
    "    )\n",
    "\n",
    "    # r2 score\n",
    "    for model in models:\n",
    "        print(\n",
    "            f\"{model[0]} r2\",\n",
    "            f\"{r2_score(y_true=y_test, y_pred=model[1].best_estimator_.predict(x_test))}\",\n",
    "        )\n",
    "    print(\n",
    "        f\"ensemble r2: {r2_score(y_true=y_test, y_pred=ensemble_predict(x_test))}\"\n",
    "    )\n",
    "\n",
    "    sys.stdout = original_stdout  # Reset the standard output to its original value\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model saving"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# Model saving\n",
    "dump(svm_random_search, \"rand_search_results/svm_random_search\")\n",
    "dump(svm_random_search.best_estimator_, \"rand_search_results/svm_best_model\")\n",
    "dump(rfr_random_search, \"rand_search_results/rfr_random_search\")\n",
    "dump(rfr_random_search.best_estimator_, \"rand_search_results/rfr_best_model\")\n",
    "dump(xgb_random_search, \"rand_search_results/xgb_random_search\")\n",
    "dump(xgb_random_search.best_estimator_, \"rand_search_results/xgb_best_model\")\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('default': venv)"
  },
  "interpreter": {
   "hash": "612fb3d9ffff20ebf687db91124ed6b2b9e249002eae363a2927c131d0f32fd3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}